Options,Selected Option
"[None, None]",
"[""that's stupid. why did they not print out an improved agenda to follow instead?\r\n\r\nwhy not prove it right there with a plan that would cover all the basics, it all they could do is debate the fact that they could, it just seems like they are only at the same level."", 'True. I think the JavaScript and the fact it uses deep learning is what gets me. However I interviewed with a finance company that said this and the business logic was switch cases in XML (honestly I wondered under my breath if a SQL db might have been better but who knows). I keep telling myself they reached out to me. Also I do want to make sure I make at least as much as my current job, taking into account I will be learning new things']","{'comment': ""that's stupid. why did they not print out an improved agenda to follow instead?\n\nwhy not prove it right there with a plan that would cover all the basics, it all they could do is debate the fact that they could, it just seems like they are only at the same level."", 'post_info': 'OpenAI’s Latest Article Hints at Their Timeline for AGI and ASI on r/singularity by ginius1s', 'comment_author': 'BeginningAmbitious89'}"
"[""I mean if you were going to take anyone at their word, it would be the people leading the world's research on the subject, would it not? Microsoft just published research today on moving LLMs up to 1 billion tokens. Huge advancements are being made, it seems more than plausible that they aren't even exaggerating at this point. Things are moving very, very quickly. And more money is being invested, which means it will move even quicker"", 'Its crazy to think humans would slow or stop technological advancement so WE CAN KEEP WORKING!??? \r\n\r\nHOW FUCKING STUPID ARE WE!??']","{'comment': 'Its crazy to think humans would slow or stop technological advancement so WE CAN KEEP WORKING!??? \n\nHOW FUCKING STUPID ARE WE!??', 'post_info': 'OpenAI’s Latest Article Hints at Their Timeline for AGI and ASI on r/singularity by ginius1s', 'comment_author': 'BeginningAmbitious89'}"
"[""Probably JavaScript/being in another industry and going to a startup as a junior. In fairness I posted this in a thread and they reached out to me. Also they are well funded and my tech friend said go for it. I just don't want to fuck up as my degree is in business"", 'True. I think the JavaScript and the fact it uses deep learning is what gets me. However I interviewed with a finance company that said this and the business logic was switch cases in XML (honestly I wondered under my breath if a SQL db might have been better but who knows). I keep telling myself they reached out to me. Also I do want to make sure I make at least as much as my current job, taking into account I will be learning new things']","{'comment': ""Probably JavaScript/being in another industry and going to a startup as a junior. In fairness I posted this in a thread and they reached out to me. Also they are well funded and my tech friend said go for it. I just don't want to fuck up as my degree is in business"", 'post_info': 'Scared Sh*tless. on r/learnprogramming by yyuyuyu2012', 'comment_author': 'yyuyuyu2012'}"
"[""Probably JavaScript/being in another industry and going to a startup as a junior. In fairness I posted this in a thread and they reached out to me. Also they are well funded and my tech friend said go for it. I just don't want to fuck up as my degree is in business"", 'It depends on the GPO Graduate Program Officer. Most US institutions offer conditional offer letters, only after submitting the certificates you will be able to register for courses. But I may be wrong.']","{'comment': ""Probably JavaScript/being in another industry and going to a startup as a junior. In fairness I posted this in a thread and they reached out to me. Also they are well funded and my tech friend said go for it. I just don't want to fuck up as my degree is in business"", 'post_info': 'Scared Sh*tless. on r/learnprogramming by yyuyuyu2012', 'comment_author': 'yyuyuyu2012'}"
"[""Probably JavaScript/being in another industry and going to a startup as a junior. In fairness I posted this in a thread and they reached out to me. Also they are well funded and my tech friend said go for it. I just don't want to fuck up as my degree is in business"", 'No doubt because humans suck for the most prt']","{'comment': 'No doubt because humans suck for the most prt', 'post_info': 'OpenAI’s Latest Article Hints at Their Timeline for AGI and ASI on r/singularity by ginius1s', 'comment_author': 'BeginningAmbitious89'}"
"['Why not use Claude 100k? It’s not local but it’s the best for long documents', ""Probably JavaScript/being in another industry and going to a startup as a junior. In fairness I posted this in a thread and they reached out to me. Also they are well funded and my tech friend said go for it. I just don't want to fuck up as my degree is in business""]","{'comment': ""Probably JavaScript/being in another industry and going to a startup as a junior. In fairness I posted this in a thread and they reached out to me. Also they are well funded and my tech friend said go for it. I just don't want to fuck up as my degree is in business"", 'post_info': 'Scared Sh*tless. on r/learnprogramming by yyuyuyu2012', 'comment_author': 'yyuyuyu2012'}"
"[""Probably JavaScript/being in another industry and going to a startup as a junior. In fairness I posted this in a thread and they reached out to me. Also they are well funded and my tech friend said go for it. I just don't want to fuck up as my degree is in business"", 'ELI5?']","{'comment': 'ELI5?', 'post_info': 'OpenAI’s Latest Article Hints at Their Timeline for AGI and ASI on r/singularity by ginius1s', 'comment_author': 'Alchemystic1123'}"
"[""Probably JavaScript/being in another industry and going to a startup as a junior. In fairness I posted this in a thread and they reached out to me. Also they are well funded and my tech friend said go for it. I just don't want to fuck up as my degree is in business"", 'im starting to get a bit disenfranchised with this sub... do you guys actually take them for their word as far as timelines go?']","{'comment': 'im starting to get a bit disenfranchised with this sub... do you guys actually take them for their word as far as timelines go?', 'post_info': 'OpenAI’s Latest Article Hints at Their Timeline for AGI and ASI on r/singularity by ginius1s', 'comment_author': 'SharpCartographer831'}"
"[""They stand to materially benefit from more AI hype precisely because they are the industry leader. That's why I'd never trust any timeline they publish, they have a financial incentive to exaggerate."", ""that's stupid. why did they not print out an improved agenda to follow instead?\r\n\r\nwhy not prove it right there with a plan that would cover all the basics, it all they could do is debate the fact that they could, it just seems like they are only at the same level.""]","{'comment': ""that's stupid. why did they not print out an improved agenda to follow instead?\n\nwhy not prove it right there with a plan that would cover all the basics, it all they could do is debate the fact that they could, it just seems like they are only at the same level."", 'post_info': 'OpenAI’s Latest Article Hints at Their Timeline for AGI and ASI on r/singularity by ginius1s', 'comment_author': 'BeginningAmbitious89'}"
"['regular old fusion is what gets hyped (sometimes with good reason).  Cold fusion not as much', 'in what way does essentially saying ""we have to learn how to control this because it could be very dangerous"" help them on a business level? If anything, it\'s the exact opposite. What you are claiming literally makes no sense']","{'comment': 'regular old fusion is what gets hyped (sometimes with good reason).  Cold fusion not as much', 'post_info': 'OpenAI’s Latest Article Hints at Their Timeline for AGI and ASI on r/singularity by ginius1s', 'comment_author': 'SharpCartographer831'}"
"[None, None]",
"['Is it not possible to use guidance with langchain? I have not tried because I am still waiting for llama.cpp support inside guidance.', ""Maybe it's a conspiracy theory but I wonder if they stopped developing or just stopped sharing their work on GitHub or maybe even got in trouble for the local support.  Microsoft is a weird sort of frenemy of local in this space..""]","{'comment': 'Is it not possible to use guidance with langchain? I have not tried because I am still waiting for llama.cpp support inside guidance.', 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'scratchr'}"
"['RAG helps, but the quality of the answer is highly dependent on the retrieval mechanism. Any poor decision during the embedding extraction pipeline can ruin the result during inference much later. It does not help the fact that LLMs do not consistently obey/disobey instructions.', 'I was experimenting with different prompts and LLMs for the case scenario to extract information from articles, and Guanaco-65B was performing well in 99% of the cases with prompts similar to this one (partly taken from Langchain documentation):  \r\n\r\n\r\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.  \r\n\\### Instruction:   \r\nExtract the following information from the text in input:  \r\n1. Article ID  \r\n2. Publication date  \r\n3. Article title  \r\nYou must format your output as a JSON value that adheres to a given ""JSON Schema"" instance.  \r\n""JSON Schema"" is a declarative language that allows you to annotate and validate JSON documents.  \r\nYour output will be parsed and type-checked according to the provided schema instance, so make sure all fields in your output match exactly!  \r\nAs an example, this text: {sample text here}  \r\nResults in the json: {provide your desired output structure}  \r\n\\### Input:   \r\n {article text}  \r\n\\### Response:  \r\nValid JSON document that adheres to the schema output schema instance {your desired schema} : \\`\\`\\`json {']","{'comment': 'I was experimenting with different prompts and LLMs for the case scenario to extract information from articles, and Guanaco-65B was performing well in 99% of the cases with prompts similar to this one (partly taken from Langchain documentation):  \n\n\nBelow is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.  \n\\### Instruction:   \nExtract the following information from the text in input:  \n1. Article ID  \n2. Publication date  \n3. Article title  \nYou must format your output as a JSON value that adheres to a given ""JSON Schema"" instance.  \n""JSON Schema"" is a declarative language that allows you to annotate and validate JSON documents.  \nYour output will be parsed and type-checked according to the provided schema instance, so make sure all fields in your output match exactly!  \nAs an example, this text: {sample text here}  \nResults in the json: {provide your desired output structure}  \n\\### Input:   \n {article text}  \n\\### Response:  \nValid JSON document that adheres to the schema output schema instance {your desired schema} : \\`\\`\\`json {', 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'TheHelpfulAssistant'}"
"[""You want to use the guidance library from MS. It's great for this."", 'Setting a high temperature parameter, is more likely to result in different outputs. \r\n\r\nYou might need to rework your prompt to prevent it from using it in the output. Maybe a command to not write anything in the prompt in the output or something.']","{'comment': ""You want to use the guidance library from MS. It's great for this."", 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'scratchr'}"
"['Rewrite your prompt', 'Thanks! You mean this? https://github.com/microsoft/guidance/']","{'comment': 'Thanks! You mean this? https://github.com/microsoft/guidance/', 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'scratchr'}"
"[""I do it by taking the message and sending it to a new instance of an LLM and say can you please write the output into JSON format please. Can I give it an empty json document with the parts I wanted to fill out and it usually fills it out pretty well. I take regular expressions and destroy all of the output. That's not a JSON object and then I use Python to validate the object before moving forward."", ""There is an unmerged PR that adds support in Oobabooga but it's easier if you just use the Guidance repo directly (they have Jupyter/Colab notebooks as well as python code samples).""]","{'comment': ""I do it by taking the message and sending it to a new instance of an LLM and say can you please write the output into JSON format please. Can I give it an empty json document with the parts I wanted to fill out and it usually fills it out pretty well. I take regular expressions and destroy all of the output. That's not a JSON object and then I use Python to validate the object before moving forward."", 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'TheHelpfulAssistant'}"
"['Langchain provides all the underlying tools you would need for generation and parsing of JSON and similar formats using for LLMs.\r\n\r\nTake a look at this:\r\n\r\nhttps://horosin.com/extracting-pdf-and-generating-json-data-with-gpts-langchain-and-nodejs', 'not only that, it\'s pretty lazy and can be particularly unhelpful due it\'s programmed morals and ethics, eg re copyright for one example, it extends to issues getting help with issues related to standards for instance\r\n\r\nthe laziness, even when told to provide complete information and do not finish early, it stops short of listing all the items asked to locate in a text or diagram, or similar every time, has to be prompted to give more, rarely can you get everything, even when very explicit as to this being the need - don\'t know if this is something that OpenAI have done to reduce load or not\r\n\r\nI asked it to provide examples of answers for my daughters english exams (it knew the book, and it knew the requirements, and my daughters teacher had not really provided examples of what a good answer might look like, though he should have, but when I asked GPT it went into moral panic about copyright, and then more moral panic about providing exam answers, I very clearly explained the issue, and how the teacher should have provided answers, and I wanted it to consider itself a teacher, and the harm that might come to a human if my daughter was so distressed about the situation she might not even attend the exam, and it cared more about doing ""the right thing"" - the right thing woudl have been to act as the teacher and provide some examples, based on another book even if this was a problem\r\n\r\nbut no, I think it has been castrated from much of it\'s effective use']","{'comment': 'not only that, it\'s pretty lazy and can be particularly unhelpful due it\'s programmed morals and ethics, eg re copyright for one example, it extends to issues getting help with issues related to standards for instance\n\nthe laziness, even when told to provide complete information and do not finish early, it stops short of listing all the items asked to locate in a text or diagram, or similar every time, has to be prompted to give more, rarely can you get everything, even when very explicit as to this being the need - don\'t know if this is something that OpenAI have done to reduce load or not\n\nI asked it to provide examples of answers for my daughters english exams (it knew the book, and it knew the requirements, and my daughters teacher had not really provided examples of what a good answer might look like, though he should have, but when I asked GPT it went into moral panic about copyright, and then more moral panic about providing exam answers, I very clearly explained the issue, and how the teacher should have provided answers, and I wanted it to consider itself a teacher, and the harm that might come to a human if my daughter was so distressed about the situation she might not even attend the exam, and it cared more about doing ""the right thing"" - the right thing woudl have been to act as the teacher and provide some examples, based on another book even if this was a problem\n\nbut no, I think it has been castrated from much of it\'s effective use', 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'scratchr'}"
"[""You want to use the guidance library from MS. It's great for this."", 'I was JUST doing this for a work project. I really like the suggestion of the MS guidance library\r\n\r\nWhat I did, is define 2-3 manual examples of what I’m wanting. Then I had GPT4 create more 20 examples following my original JSON output example. \r\n\r\nThen embedded that in my prompt, before giving the task at hand']","{'comment': ""You want to use the guidance library from MS. It's great for this."", 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'scratchr'}"
"['Thanks! You mean this? https://github.com/microsoft/guidance/', ""u/Smallpaul, you're right that a sustainable project is never a certainty, certainly with big tech's history. Yet I don't see Microsoft abandoning LLM controlling projects anytime soon and together with their OpenAI partnership, even ending up being quite potent. So far, there are no options to integrate them, but they do seem aware. ([https://github.com/microsoft/guidance/discussions/200](https://github.com/microsoft/guidance/discussions/200))\r\n\r\n&#x200B;\r\n\r\nu/seanstar555 Semantic is indeed a full on sdk. They never made a comparison with LangChain because that wasn't their focus at the moment (according to: [https://github.com/microsoft/semantic-kernel/discussions/1326](https://github.com/microsoft/semantic-kernel/discussions/1326)). Yet I was hoping that someone with experience in both might have a cent or two to say as a form of comparison. \r\n\r\nIts indeed tricky to peek even slightly into the future, but I was seeking other people's experiences to make up my own mind as to how it might look. \r\n\r\nCurrently tipping toward LangChain because of the speed at which I can get my implementation done. I reckon I'll just have to spend some extra effort and time in the future on custom components.""]","{'comment': ""u/Smallpaul, you're right that a sustainable project is never a certainty, certainly with big tech's history. Yet I don't see Microsoft abandoning LLM controlling projects anytime soon and together with their OpenAI partnership, even ending up being quite potent. So far, there are no options to integrate them, but they do seem aware. ([https://github.com/microsoft/guidance/discussions/200](https://github.com/microsoft/guidance/discussions/200))\n\n&#x200B;\n\nu/seanstar555 Semantic is indeed a full on sdk. They never made a comparison with LangChain because that wasn't their focus at the moment (according to: [https://github.com/microsoft/semantic-kernel/discussions/1326](https://github.com/microsoft/semantic-kernel/discussions/1326)). Yet I was hoping that someone with experience in both might have a cent or two to say as a form of comparison. \n\nIts indeed tricky to peek even slightly into the future, but I was seeking other people's experiences to make up my own mind as to how it might look. \n\nCurrently tipping toward LangChain because of the speed at which I can get my implementation done. I reckon I'll just have to spend some extra effort and time in the future on custom components."", 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'TheHelpfulAssistant'}"
"[""You want to use the guidance library from MS. It's great for this."", 'I cannot use transformers directly due to insufficient hardware. As to why and how, as I said I have not been able to try either due to the hopefully soon to be fixed missing implementation of llama.cpp and reading about the architecture is different to attempting to use it, at least to me as I’m rather hands on. \r\n\r\nIn essence I’m not planning on holding multiple instances of an LLM alive, but sequentially. Llama.cpp for example allows model persistence so even when the task is done and a python program (agent?) is finished, the model is not unloaded and can be reused by the next program.']","{'comment': ""You want to use the guidance library from MS. It's great for this."", 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'scratchr'}"
"['I understand how guidance works in theory: it\'s doing max_tokens=1 and playing with logit propabilities so the output can always be constrained.  This is a great idea!  But they\'ve created a highly opinionated implementation based on a custom markup language that they ""execute"" in entirely unclear ways.\r\n\r\nIf guidance code could be written via plain python APIs it could be 10x more useful imo', 'That sounds like the big category of hard things is all about getting the outputs of the LLM step right.']","{'comment': 'That sounds like the big category of hard things is all about getting the outputs of the LLM step right.', 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'scratchr'}"
"[None, None]",
"['Yes', 'Amazing! This is good advice!']","{'comment': 'Yes', 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'scratchr'}"
"[""u/gamesntech Got it, thanks. I was wondering if CoT could help.. adding a rationale or the schema links along with the Text to SQL pairs while fine tuning. This way, the precision could improve. Building CoT datasets is a cumbersome task though, there aren't any available as far as i know."", 'Hi what do Foo or bar mean in this case? Thanks']","{'comment': 'Hi what do Foo or bar mean in this case? Thanks', 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'TheHelpfulAssistant'}"
"['not only that, it\'s pretty lazy and can be particularly unhelpful due it\'s programmed morals and ethics, eg re copyright for one example, it extends to issues getting help with issues related to standards for instance\r\n\r\nthe laziness, even when told to provide complete information and do not finish early, it stops short of listing all the items asked to locate in a text or diagram, or similar every time, has to be prompted to give more, rarely can you get everything, even when very explicit as to this being the need - don\'t know if this is something that OpenAI have done to reduce load or not\r\n\r\nI asked it to provide examples of answers for my daughters english exams (it knew the book, and it knew the requirements, and my daughters teacher had not really provided examples of what a good answer might look like, though he should have, but when I asked GPT it went into moral panic about copyright, and then more moral panic about providing exam answers, I very clearly explained the issue, and how the teacher should have provided answers, and I wanted it to consider itself a teacher, and the harm that might come to a human if my daughter was so distressed about the situation she might not even attend the exam, and it cared more about doing ""the right thing"" - the right thing woudl have been to act as the teacher and provide some examples, based on another book even if this was a problem\r\n\r\nbut no, I think it has been castrated from much of it\'s effective use', 'Hardly, since you did not post your prompt. But for this tiny bit, I\'d expect better results from something like ""respond only with blablabla"", if thats in a promt setup where you are talking to an assistant. Your general prompt format is fine? I think Aeroboros is a bit different from normal vicuna 1.1.']","{'comment': 'not only that, it\'s pretty lazy and can be particularly unhelpful due it\'s programmed morals and ethics, eg re copyright for one example, it extends to issues getting help with issues related to standards for instance\n\nthe laziness, even when told to provide complete information and do not finish early, it stops short of listing all the items asked to locate in a text or diagram, or similar every time, has to be prompted to give more, rarely can you get everything, even when very explicit as to this being the need - don\'t know if this is something that OpenAI have done to reduce load or not\n\nI asked it to provide examples of answers for my daughters english exams (it knew the book, and it knew the requirements, and my daughters teacher had not really provided examples of what a good answer might look like, though he should have, but when I asked GPT it went into moral panic about copyright, and then more moral panic about providing exam answers, I very clearly explained the issue, and how the teacher should have provided answers, and I wanted it to consider itself a teacher, and the harm that might come to a human if my daughter was so distressed about the situation she might not even attend the exam, and it cared more about doing ""the right thing"" - the right thing woudl have been to act as the teacher and provide some examples, based on another book even if this was a problem\n\nbut no, I think it has been castrated from much of it\'s effective use', 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'scratchr'}"
"[""Hallucinations, or more correctly...Confabulations. I want to be able to get consistent results out of my LLMs and for it to be more deterministic i.e. not make stuff up. \r\n\r\nI've read than RAG can help with this and that might the future..."", ""You want to use the guidance library from MS. It's great for this.""]","{'comment': ""You want to use the guidance library from MS. It's great for this."", 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'scratchr'}"
"['Langchain provides all the underlying tools you would need for generation and parsing of JSON and similar formats using for LLMs.\r\n\r\nTake a look at this:\r\n\r\nhttps://horosin.com/extracting-pdf-and-generating-json-data-with-gpts-langchain-and-nodejs', ""On what planet are Semantic Kernel and Guidance closed source? Both are released under the MIT License, as noted plainly on the GitHub project homepages for each.\r\n\r\nI prefer Guidance to LangChain. LangChain has a slightly richer set of features, but as a software project it's a mess. In the end I'm much more productive with guidance - it's easier to use, the examples and source code are clearer and better-organized, and they seem to have a plan with respect to a roadmap.""]","{'comment': 'Langchain provides all the underlying tools you would need for generation and parsing of JSON and similar formats using for LLMs.\n\nTake a look at this:\n\nhttps://horosin.com/extracting-pdf-and-generating-json-data-with-gpts-langchain-and-nodejs', 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'TheHelpfulAssistant'}"
"[""From what I could gather giving it a brief look, they're two completely different things that just happen to share similar markup for the prompting."", ""There's no guarantee or reason to believe that they would be more sustainable and well-researched going forward. Big companies kill projects all of the time.\r\n\r\nAlso: are Semantic Kernel and Guidance designed to be used together? My quick skim didn't provide any evidence that they are. If they are two unrelated projects then there's no reason to think of them as a unit.""]","{'comment': ""There's no guarantee or reason to believe that they would be more sustainable and well-researched going forward. Big companies kill projects all of the time.\n\nAlso: are Semantic Kernel and Guidance designed to be used together? My quick skim didn't provide any evidence that they are. If they are two unrelated projects then there's no reason to think of them as a unit."", 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'scratchr'}"
"[""My hope is that it was just the summer vacation availability and they'll be back to supporting the project, as it was by far the best when working with local models.\r\n\r\nLMQL is also really promising, and is maintained, they have a great roadmap of features, and are working on caching so that's gonna make it much faster than it is right now."", ""On what planet are Semantic Kernel and Guidance closed source? Both are released under the MIT License, as noted plainly on the GitHub project homepages for each.\r\n\r\nI prefer Guidance to LangChain. LangChain has a slightly richer set of features, but as a software project it's a mess. In the end I'm much more productive with guidance - it's easier to use, the examples and source code are clearer and better-organized, and they seem to have a plan with respect to a roadmap.""]","{'comment': ""My hope is that it was just the summer vacation availability and they'll be back to supporting the project, as it was by far the best when working with local models.\n\nLMQL is also really promising, and is maintained, they have a great roadmap of features, and are working on caching so that's gonna make it much faster than it is right now."", 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'TheHelpfulAssistant'}"
"[""You want to use the guidance library from MS. It's great for this."", 'Semantic Kernel is the best: [https://www.youtube.com/watch?v=90hhJHTWz50](https://www.youtube.com/watch?v=90hhJHTWz50)']","{'comment': 'Semantic Kernel is the best: [https://www.youtube.com/watch?v=90hhJHTWz50](https://www.youtube.com/watch?v=90hhJHTWz50)', 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'TheHelpfulAssistant'}"
"['The hardest part for me currently is the logistics of handling large amounts of user data. In my current project the system runs bare metal (locally) which means that caching models can be an issue, depending on the amount of models used at a time. For context this project allows you to identify trained variances in text against a large set of models. I also plan to make it possible to train custom models which again will need to be stored for use.', 'Give it a name and a prompt along the lines of ""as *name*, you only provide answers in JSON format\r\n\r\n\r\nThen hello *name*, please do the following:\r\n1.\r\n2.\r\nProvide your answers in JSON with the following keys:\r\nFoo,bar']","{'comment': 'The hardest part for me currently is the logistics of handling large amounts of user data. In my current project the system runs bare metal (locally) which means that caching models can be an issue, depending on the amount of models used at a time. For context this project allows you to identify trained variances in text against a large set of models. I also plan to make it possible to train custom models which again will need to be stored for use.', 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'scratchr'}"
"['not only that, it\'s pretty lazy and can be particularly unhelpful due it\'s programmed morals and ethics, eg re copyright for one example, it extends to issues getting help with issues related to standards for instance\r\n\r\nthe laziness, even when told to provide complete information and do not finish early, it stops short of listing all the items asked to locate in a text or diagram, or similar every time, has to be prompted to give more, rarely can you get everything, even when very explicit as to this being the need - don\'t know if this is something that OpenAI have done to reduce load or not\r\n\r\nI asked it to provide examples of answers for my daughters english exams (it knew the book, and it knew the requirements, and my daughters teacher had not really provided examples of what a good answer might look like, though he should have, but when I asked GPT it went into moral panic about copyright, and then more moral panic about providing exam answers, I very clearly explained the issue, and how the teacher should have provided answers, and I wanted it to consider itself a teacher, and the harm that might come to a human if my daughter was so distressed about the situation she might not even attend the exam, and it cared more about doing ""the right thing"" - the right thing woudl have been to act as the teacher and provide some examples, based on another book even if this was a problem\r\n\r\nbut no, I think it has been castrated from much of it\'s effective use', 'I have a character based voice bot I’m working on now and the most frustrating thing I’ve encountered in the late stages of the project is balancing the prompt with the fine tuned model. Some bot characters will have perfect personalities and identities while others, seemingly with the exact same formula, will hallucinate. Changing one word in the prompt or one training example amongst 100’s of other training examples can totally skew the bot’s personality in unpredictable ways. Feels a lot closer to an art project than a programming project.']","{'comment': 'not only that, it\'s pretty lazy and can be particularly unhelpful due it\'s programmed morals and ethics, eg re copyright for one example, it extends to issues getting help with issues related to standards for instance\n\nthe laziness, even when told to provide complete information and do not finish early, it stops short of listing all the items asked to locate in a text or diagram, or similar every time, has to be prompted to give more, rarely can you get everything, even when very explicit as to this being the need - don\'t know if this is something that OpenAI have done to reduce load or not\n\nI asked it to provide examples of answers for my daughters english exams (it knew the book, and it knew the requirements, and my daughters teacher had not really provided examples of what a good answer might look like, though he should have, but when I asked GPT it went into moral panic about copyright, and then more moral panic about providing exam answers, I very clearly explained the issue, and how the teacher should have provided answers, and I wanted it to consider itself a teacher, and the harm that might come to a human if my daughter was so distressed about the situation she might not even attend the exam, and it cared more about doing ""the right thing"" - the right thing woudl have been to act as the teacher and provide some examples, based on another book even if this was a problem\n\nbut no, I think it has been castrated from much of it\'s effective use', 'post_info': 'How does Microsoft Guidance work? on r/LocalLLaMA by T_hank', 'comment_author': 'scratchr'}"
